{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T18:47:09.862589600Z",
     "start_time": "2024-08-28T18:47:09.827307900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--alpha ALPHA] [--beta BETA]\n",
      "                             [--batch_size BATCH_SIZE] [--class_num CLASS_NUM]\n",
      "                             [--device DEVICE] [--decay_rate DECAY_RATE]\n",
      "                             [--decay_step DECAY_STEP] [--dropout DROPOUT]\n",
      "                             [--d_model D_MODEL] [--d_text D_TEXT]\n",
      "                             [--img_size IMG_SIZE] [--k K] [--lr LR] [--l2 L2]\n",
      "                             [--num_class NUM_CLASS] [--num_epoch NUM_EPOCH]\n",
      "                             [--num_filter NUM_FILTER] [--num_layer NUM_LAYER]\n",
      "                             [--patch_size PATCH_SIZE] [--patience PATIENCE]\n",
      "                             [--seed SEED] [--seq_len SEQ_LEN]\n",
      "                             [--shuffle SHUFFLE] [--use_parallel USE_PARALLEL]\n",
      "                             [--vocab_size VOCAB_SIZE] [--data_path DATA_PATH]\n",
      "                             [--img_data_path IMG_DATA_PATH]\n",
      "                             [--output_path OUTPUT_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\jx\\AppData\\Roaming\\jupyter\\runtime\\kernel-ccbf1a93-632f-497d-b451-7ee6d7a20235.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "An Lao\n",
    "\"\"\"\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"expandable_segments:True\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from arguments import parse_arguments\n",
    "from data_loader import *\n",
    "from datasets import MyDataset\n",
    "from model import FSRU\n",
    "from loss import FullContrastiveLoss, SelfContrastiveLoss\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = torch.as_tensor(x, dtype=torch.float32).cuda()\n",
    "    else:\n",
    "        x = torch.as_tensor(x, dtype=torch.float32)\n",
    "    return x\n",
    "\n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_kfold_data(k, i, text, image, label):\n",
    "    fold_size = text.shape[0] // k\n",
    "\n",
    "    val_start = i * fold_size\n",
    "    if i != k - 1:\n",
    "        val_end = (i + 1) * fold_size\n",
    "        text_valid, image_valid, label_valid = text[val_start:val_end], image[val_start:val_end], label[\n",
    "                                                                                                  val_start:val_end]\n",
    "        text_train = np.concatenate((text[0:val_start], text[val_end:]), axis=0)\n",
    "        image_train = np.concatenate((image[0:val_start], image[val_end:]), axis=0)\n",
    "        label_train = np.concatenate((label[0:val_start], label[val_end:]), axis=0)\n",
    "    else:\n",
    "        text_valid, image_valid, label_valid = text[val_start:], image[val_start:], label[val_start:]\n",
    "        text_train = text[0:val_start]\n",
    "        image_train = image[0:val_start]\n",
    "        label_train = label[0:val_start]\n",
    "\n",
    "    return text_train, image_train, label_train, text_valid, image_valid, label_valid\n",
    "\n",
    "\n",
    "def count(labels):\n",
    "    r, nr = 0, 0\n",
    "    for label in labels:\n",
    "        if label == 0:\n",
    "            nr += 1\n",
    "        elif label == 1:\n",
    "            r += 1\n",
    "    return r, nr\n",
    "\n",
    "\n",
    "def shuffle_dataset(text, image, label):\n",
    "    assert len(text) == len(image) == len(label)\n",
    "    rp = np.random.permutation(len(text))\n",
    "    text = text[rp]\n",
    "    image = image[rp]\n",
    "    label = label[rp]\n",
    "\n",
    "    return text, image, label\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # device = torch.device(args.device)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    print('Loading data ...')\n",
    "\n",
    "    text, image, label, W = load_data(args)\n",
    "    text, image, label = shuffle_dataset(text, image, label)\n",
    "\n",
    "    K = args.k\n",
    "    print('Using K:', K, 'fold cross validation...')\n",
    "\n",
    "    valid_acc_sum, valid_pre_sum, valid_recall_sum, valid_f1_sum = 0., 0., 0., 0.\n",
    "    valid_nr_pre_sum, valid_nr_recall_sum, valid_nr_f1_sum = 0., 0., 0.\n",
    "    valid_r_pre_sum, valid_r_recall_sum, valid_r_f1_sum = 0., 0., 0.\n",
    "\n",
    "    for i in range(K):\n",
    "        train, valid = {}, {}\n",
    "        print('-' * 25, 'Fold:', i + 1, '-' * 25)\n",
    "        train['text'], train['image'], train['label'], valid['text'], valid['image'], valid['label'] = \\\n",
    "            get_kfold_data(K, i, text, image, label)\n",
    "\n",
    "        train_loader = DataLoader(dataset=MyDataset(train), batch_size=args.batch_size, shuffle=False)\n",
    "        valid_loader = DataLoader(dataset=MyDataset(valid), batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        print('Building model...')\n",
    "\n",
    "        model = FSRU(W, args.vocab_size, args.d_text, args.seq_len, args.img_size, args.patch_size, args.d_model,\n",
    "                     args.num_filter, args.num_class, args.num_layer, args.dropout)\n",
    "        model.to(device)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"CUDA\")\n",
    "            model.cuda()\n",
    "\n",
    "        # Loss and Optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "\n",
    "        best_valid_acc, best_valid_pre, best_valid_recall, best_valid_f1 = 0., 0., 0., 0.\n",
    "        best_valid_nr_pre, best_valid_nr_f1, best_valid_nr_recall, = 0., 0., 0.\n",
    "        best_valid_r_pre, best_valid_r_recall, best_valid_r_f1 = 0., 0., 0.\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for epoch in range(args.num_epoch):\n",
    "            print('epoch: ', epoch)\n",
    "            train_losses, valid_losses, train_acc, valid_acc = [], [], [], []\n",
    "            start_time = time.time()\n",
    "            cls_loss = []\n",
    "\n",
    "            # train\n",
    "            model.train()\n",
    "            for j, (train_text, train_image, train_labels) in enumerate(train_loader):\n",
    "                num_r, num_nr = count(train_labels)\n",
    "                train_text, train_image, train_labels = to_var(train_text), to_var(train_image), to_var(train_labels)\n",
    "\n",
    "                # Forward + Backward + Optimize\n",
    "                criterion_full = FullContrastiveLoss(batch_size=train_text.shape[0], num_r=num_r, num_nr=num_nr)\n",
    "                criterion_self = SelfContrastiveLoss(batch_size=train_text.shape[0])\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                text_outputs, image_outputs, label_outputs, _ = model(train_text, train_image)\n",
    "\n",
    "                loss = criterion(label_outputs, train_labels.long())\n",
    "                loss_full = criterion_full(text_outputs, image_outputs, train_labels.long())\n",
    "                loss_self = criterion_self(text_outputs, image_outputs)\n",
    "                train_loss = loss + args.alpha * loss_full + args.beta * loss_self\n",
    "                train_loss.backward()\n",
    "                pred = torch.max(label_outputs, 1)[1]\n",
    "                train_accuracy = torch.eq(train_labels, pred.squeeze()).float().mean()  # .sum() / len(train_labels)\n",
    "                train_losses.append(train_loss.item())\n",
    "                train_acc.append(train_accuracy.item())\n",
    "                cls_loss.append(loss.item())\n",
    "\n",
    "                # Clean up GPU memory\n",
    "                del loss, loss_full, loss_self, train_loss, pred, train_accuracy\n",
    "                del train_text, train_image, train_labels, label_outputs\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch % args.decay_step == 0:\n",
    "                for params in optimizer.param_groups:\n",
    "                    params['lr'] *= args.decay_rate\n",
    "\n",
    "            # valid\n",
    "            model.eval()\n",
    "            valid_pred, valid_y = [], []\n",
    "            with torch.no_grad():\n",
    "                for j, (valid_text, valid_image, valid_labels) in enumerate(valid_loader):\n",
    "                    valid_text, valid_image, valid_labels = to_var(valid_text), to_var(valid_image), to_var(\n",
    "                        valid_labels)\n",
    "\n",
    "                    _, _, label_outputs, _ = model(valid_text, valid_image)\n",
    "                    label_outputs = F.softmax(label_outputs, dim=1)\n",
    "                    pred = torch.max(label_outputs, 1)[1]\n",
    "                    if j == 0:\n",
    "                        valid_pred = to_np(pred.squeeze())\n",
    "                        valid_y = to_np(valid_labels.squeeze())\n",
    "                    else:\n",
    "                        valid_pred = np.concatenate((valid_pred, to_np(pred.squeeze())), axis=0)\n",
    "                        valid_y = np.concatenate((valid_y, to_np(valid_labels.squeeze())), axis=0)\n",
    "\n",
    "                    # Clean up GPU memory\n",
    "                    del valid_text, valid_image, valid_labels, label_outputs, pred\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            # cur_valid_acc = np.mean(valid_acc)\n",
    "            cur_valid_acc = metrics.accuracy_score(valid_y, valid_pred)\n",
    "            valid_pre = metrics.precision_score(valid_y, valid_pred, average='macro')\n",
    "            valid_recall = metrics.recall_score(valid_y, valid_pred, average='macro')\n",
    "            valid_f1 = metrics.f1_score(valid_y, valid_pred, average='macro')\n",
    "            duration = time.time() - start_time\n",
    "            mean_loss = np.mean(train_losses)\n",
    "            mean_train_acc = np.mean(train_acc)\n",
    "            print('Epoch[{}/{}], Duration:{:.8f}, Loss:{:.8f}, Train_Accuracy:{:.5f}, Valid_accuracy:{:.5f}'.format(\n",
    "                epoch + 1, args.num_epoch, duration, mean_loss, mean_train_acc, cur_valid_acc))\n",
    "            loss_list.append(np.mean(cls_loss))\n",
    "            acc_list.append(cur_valid_acc)\n",
    "\n",
    "            if cur_valid_acc > best_valid_acc:\n",
    "                best_valid_acc = cur_valid_acc\n",
    "                best_valid_pre = valid_pre\n",
    "                best_valid_recall = valid_recall\n",
    "                best_valid_f1 = valid_f1\n",
    "                print('Best...')\n",
    "                # print(metrics.classification_report(valid_y, valid_pred, digits=4))\n",
    "                target_names = ['non-rumor', 'rumor']\n",
    "                report = metrics.classification_report(valid_y, valid_pred, output_dict=True, target_names=target_names)\n",
    "                nr_report = report['non-rumor']\n",
    "                best_valid_nr_pre = nr_report['precision']\n",
    "                best_valid_nr_recall = nr_report['recall']\n",
    "                best_valid_nr_f1 = nr_report['f1-score']\n",
    "                r_report = report['rumor']\n",
    "                best_valid_r_pre = r_report['precision']\n",
    "                best_valid_r_recall = r_report['recall']\n",
    "                best_valid_r_f1 = r_report['f1-score']\n",
    "\n",
    "        valid_acc_sum += best_valid_acc\n",
    "        valid_pre_sum += best_valid_pre\n",
    "        valid_recall_sum += best_valid_recall\n",
    "        valid_f1_sum += best_valid_f1\n",
    "        print('best_valid_acc:{:.6f}, best_valid_pre:{:.6f}, best_valid_recall:{:.6f}, best_valid_f1:{:.6f}'.\n",
    "              format(best_valid_acc, best_valid_pre, best_valid_recall, best_valid_f1))\n",
    "        valid_nr_pre_sum += best_valid_nr_pre\n",
    "        valid_nr_recall_sum += best_valid_nr_recall\n",
    "        valid_nr_f1_sum += best_valid_nr_f1\n",
    "        valid_r_pre_sum += best_valid_r_pre\n",
    "        valid_r_recall_sum += best_valid_r_recall\n",
    "        valid_r_f1_sum += best_valid_r_f1\n",
    "\n",
    "        # Clean up GPU memory\n",
    "        del train, valid, train_loader, valid_loader\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print('=' * 40)\n",
    "    print('Accuracy:{:.5f}, F1:{:.5f}'.format(valid_acc_sum / K, valid_f1_sum / K))\n",
    "    print('Rumor Precision:{:.5f}, Rumor Recall:{:.5f}, Rumor F1:{:.5f}'.format(\n",
    "        valid_r_pre_sum / K, valid_r_recall_sum / K, valid_r_f1_sum / K))\n",
    "    print('Non-Rumor Precision:{:.5f}, Non-Rumor Recall:{:.5f}, Non-Rumor F1:{:.5f}'.format(\n",
    "        valid_nr_pre_sum / K, valid_nr_recall_sum / K, valid_nr_f1_sum / K))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parse = argparse.ArgumentParser()\n",
    "    parser = parse_arguments(parse)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
